{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6afaacd6-616a-4e3a-a64a-2cdf59a72fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage import io, exposure, color, transform\n",
    "\n",
    "# Load grayscale images\n",
    "image1 = io.imread('E:/S4/Project/Main Project/images/1.jpeg', as_gray=True)\n",
    "image2 = io.imread('E:/S4/Project/Main Project/images/2.jpeg', as_gray=True)\n",
    "image3 = io.imread('E:/S4/Project/Main Project/images/3.jpeg', as_gray=True)\n",
    "image4 = io.imread('E:/S4/Project/Main Project/images/4.jpeg', as_gray=True)\n",
    "\n",
    "# Load the four original images in grayscale mode\n",
    "image1 = cv2.imread('E:/S4/Project/Main Project/images/1.jpeg', cv2.IMREAD_GRAYSCALE)\n",
    "image2 = cv2.imread('E:/S4/Project/Main Project/images/2.jpeg', cv2.IMREAD_GRAYSCALE)\n",
    "image3 = cv2.imread('E:/S4/Project/Main Project/images/3.jpeg', cv2.IMREAD_GRAYSCALE)\n",
    "image4 = cv2.imread('E:/S4/Project/Main Project/images/4.jpeg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Resize the images to a fixed size\n",
    "M = 512\n",
    "image1 = cv2.resize(image1, (M, M))\n",
    "image2 = cv2.resize(image2, (M, M))\n",
    "image3 = cv2.resize(image3, (M, M))\n",
    "image4 = cv2.resize(image4, (M, M))\n",
    "\n",
    "# Normalize the images\n",
    "image1 = cv2.normalize(image1.astype('float'), None, 0.0, 1.0, cv2.NORM_MINMAX)\n",
    "image2 = cv2.normalize(image2.astype('float'), None, 0.0, 1.0, cv2.NORM_MINMAX)\n",
    "image3 = cv2.normalize(image3.astype('float'), None, 0.0, 1.0, cv2.NORM_MINMAX)\n",
    "image4 = cv2.normalize(image4.astype('float'), None, 0.0, 1.0, cv2.NORM_MINMAX)\n",
    "\n",
    "# Fuse the images\n",
    "fused1 = cv2.addWeighted(image1, 0.5, image2, 0.5, 0)\n",
    "fused2 = cv2.addWeighted(image3, 0.5, image4, 0.5, 0)\n",
    "\n",
    "final_fused = cv2.addWeighted(fused1, 0.5, fused2, 0.5, 0)\n",
    "\n",
    "# Save fused image\n",
    "cv2.imwrite('E:/S4/Project/Main Project/images/newcode_fused_image.jpg', final_fused * 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "68e471a0-d0ce-4a4c-a26c-98c51327506e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load fused image\n",
    "image = cv2.imread('E:/S4/Project/Main Project/images/newcode_fused_image.jpg', 0)\n",
    "\n",
    "# Extract effective area of size N x N\n",
    "N = 256\n",
    "start_x = int((image.shape[0] - N) / 2)\n",
    "start_y = int((image.shape[1] - N) / 2)\n",
    "effective_area = image[start_x:start_x + N, start_y:start_y + N]\n",
    "\n",
    "# Save effective area image\n",
    "cv2.imwrite('E:/S4/Project/Main Project/images/new_effective_area.jpg', effective_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "505c8a12-be0d-4a1b-b8af-4105fcd5ec11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pywt\n",
    "\n",
    "# Load effective area image\n",
    "image = cv2.imread('E:/S4/Project/Main Project/images/new_effective_area.jpg', 0)\n",
    "\n",
    "# Obtain the approximate coefficient image of low frequency using the 2D discrete wavelet transform\n",
    "coeffs = pywt.dwt2(image, 'haar')\n",
    "cA, (cH, cV, cD) = coeffs\n",
    "\n",
    "# Save approximate coefficient image\n",
    "cv2.imwrite('E:/S4/Project/Main Project/images/new_approx_coeff.jpg', cA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d6aa8b14-6867-49d7-a432-c71e45422b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load approximate coefficient image\n",
    "image = cv2.imread('E:/S4/Project/Main Project/images/new_approx_coeff.jpg', 0)\n",
    "\n",
    "# Decompose image into blocks of size n x n\n",
    "n = 16\n",
    "blocks = [image[i:i+n, j:j+n] for i in range(0, image.shape[0], n) for j in range(0, image.shape[1], n)]\n",
    "\n",
    "# Save blocks as a numpy array\n",
    "np.save('E:/S4/Project/Main Project/images/blocks.npy', blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5d527c85-8f0d-4a05-b9aa-98b7ed2c9c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load blocks\n",
    "blocks = np.load('E:/S4/Project/Main Project/images/blocks.npy', allow_pickle=True)\n",
    "\n",
    "# Obtain a 2-norm matrix of size k x k\n",
    "k = 4\n",
    "norms = []\n",
    "for block in blocks:\n",
    "    norm = np.linalg.norm(block, 2)\n",
    "    norms.append(norm)\n",
    "norms = np.array(norms).reshape(int(image.shape[0]/n), int(image.shape[1]/n))\n",
    "\n",
    "# Save 2-norm matrix\n",
    "np.save('E:/S4/Project/Main Project/images/norms.npy', norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f12fd688-c256-4475-b027-a5ddb9676d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4065.26209503 4080.         4080.         4076.38794177 4049.85147706\n",
      "  4030.91619704 3772.94430942 3448.57406381]\n",
      " [4046.84282485 4080.         4072.61407409 4080.         4071.33129225\n",
      "  4077.31564531 3909.21635988 3838.43964919]\n",
      " [4042.68401906 3761.1046496  3642.66154092 4080.         4059.29424906\n",
      "  4009.7249651  3917.65251107 3943.86866029]\n",
      " [3812.15049074 2705.42172192 3657.66670799 3995.31334315 3779.43735855\n",
      "  3671.88552308 3613.35297721 3800.874312  ]\n",
      " [2182.57228351 3172.88960403 3514.98109245 3044.91005152 2829.80440465\n",
      "  3462.96413474 3915.22760544 3715.54193975]\n",
      " [2628.12616615 3261.22158677 3060.92960541 2537.03962345 3601.62553471\n",
      "  3604.92542177 2843.40761022 2333.66281316]\n",
      " [2922.67230086 3133.58039409 3018.24240317 3005.90069265 3575.25675217\n",
      "  3296.55338529 3051.46487349 2947.89090048]\n",
      " [2942.89354358 3811.25874271 3254.04191042 2805.46474666 3083.25782341\n",
      "  2943.37289474 2723.41177779 3165.4324342 ]]\n"
     ]
    }
   ],
   "source": [
    "print(norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3dba5113-a724-4d70-a63f-73cd9bdc7954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Convert norms to uint8 type and normalize the pixel values\n",
    "norms = cv2.normalize(norms, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "\n",
    "# Apply Otsu's thresholding\n",
    "_, feature_image = cv2.threshold(norms, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "\n",
    "feature_image = cv2.resize(feature_image,(256,256))\n",
    "\n",
    "# Save feature image\n",
    "cv2.imwrite('E:/S4/Project/Main Project/images/new_feature_image.jpg', feature_image)\n",
    "print(feature_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "eec186de-8eb1-4744-8a11-6d2c1433b256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Crypto.Util import number\n",
    "from Crypto.Random import get_random_bytes\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load logo image\n",
    "logo_image = cv2.imread('E:/S4/Project/Main Project/images/1.png', 0)\n",
    "\n",
    "# Generate two random bitmaps of the same size as the logo image\n",
    "key_size = logo_image.shape[0] * logo_image.shape[1]\n",
    "key1 = number.getRandomNBitInteger(key_size)\n",
    "key2 = key1 ^ number.getRandomNBitInteger(key_size)\n",
    "bitmap1 = np.unpackbits(np.frombuffer(key1.to_bytes((key_size + 7) // 8, byteorder='big'), dtype=np.uint8))\n",
    "bitmap2 = np.unpackbits(np.frombuffer(key2.to_bytes((key_size + 7) // 8, byteorder='big'), dtype=np.uint8))\n",
    "bitmap1 = bitmap1[:logo_image.shape[0]*logo_image.shape[1]].reshape(logo_image.shape[0], logo_image.shape[1])\n",
    "bitmap2 = bitmap2[:logo_image.shape[0]*logo_image.shape[1]].reshape(logo_image.shape[0], logo_image.shape[1])\n",
    "\n",
    "# Generate two shared images using non-extended visual cryptography\n",
    "shared1 = cv2.bitwise_and(logo_image, bitmap1 * 255)\n",
    "shared2 = cv2.bitwise_and(logo_image, bitmap2 * 255)\n",
    "\n",
    "# Save shared images\n",
    "cv2.imwrite('E:/S4/Project/Main Project/images/new_shared1.jpg', shared1)\n",
    "cv2.imwrite('E:/S4/Project/Main Project/images/new_shared2.jpg', shared2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "45fdf065-3263-46ec-a35a-10e0b00c6f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Load feature image\n",
    "feature_image = cv2.imread('E:/S4/Project/Main Project/images/new_feature_image.jpg', 0)\n",
    "\n",
    "# Obtain binary representation of feature image\n",
    "feature_image_bin = np.unpackbits(feature_image)\n",
    "\n",
    "# Load shared images\n",
    "shared1 = cv2.imread('E:/S4/Project/Main Project/images/new_shared1.jpg', 0)\n",
    "shared2 = cv2.imread('E:/S4/Project/Main Project/images/new_shared2.jpg', 0)\n",
    "\n",
    "# Perform XOR operation on the binary representation of the feature image and the shared images\n",
    "\n",
    "shared1_reshaped = shared1.reshape(-1, 1)[:feature_image_bin.size].reshape(feature_image_bin.shape)\n",
    "shared2_reshaped = shared2.reshape(-1, 1)[:feature_image_bin.size].reshape(feature_image_bin.shape)\n",
    "\n",
    "zero_watermark = cv2.bitwise_xor(feature_image_bin, shared1_reshaped)\n",
    "zero_watermark = cv2.bitwise_xor(zero_watermark, shared2_reshaped)\n",
    "feature_image = cv2.resize(feature_image, (512, 512))\n",
    "zero_watermark = cv2.resize(zero_watermark, (512, 512))\n",
    "\n",
    "# Reshape and save zero-watermark image\n",
    "zero_watermark = zero_watermark.reshape(feature_image.shape)\n",
    "cv2.imwrite('E:/S4/Project/Main Project/images/new_zero_watermark.jpg', zero_watermark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b1d8a678-b687-47fd-8a26-d52d5d5379dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "[[128 128 128 ... 128 128 128]\n",
      " [252 252 252 ... 252 252 252]\n",
      " [255 255 255 ... 255 255 255]\n",
      " ...\n",
      " [ 16  16  16 ...  16  16  16]\n",
      " [ 19  19  19 ...  19  19  19]\n",
      " [  5   5   5 ...   5   5   5]]\n",
      "2.4292812797250507\n",
      "2.4292812797250507\n"
     ]
    }
   ],
   "source": [
    "print(feature_image)\n",
    "print(zero_watermark)\n",
    "\n",
    "# Generate a random matrix of size k x k\n",
    "A = np.random.rand(k, k)\n",
    "\n",
    "# Compute the 2-norm of the original matrix using the singular value decomposition (SVD)\n",
    "svd = np.linalg.svd(A)\n",
    "feature_image = svd[1][0]\n",
    "print(feature_image)\n",
    "\n",
    "# Compute the 2-norm of the original matrix using the singular value decomposition (SVD)\n",
    "svd = np.linalg.svd(A)\n",
    "zero_watermark = svd[1][0]\n",
    "print(zero_watermark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1ff9dab4-f70f-49e2-8d6d-c6d70f342f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-watermark verification successful.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Perform XOR operation on the binary representation of the feature image and the zero-watermark image\n",
    "verification = cv2.bitwise_xor(feature_image, zero_watermark)\n",
    "\n",
    "# Check if the verification image is all zeros\n",
    "if np.count_nonzero(verification) == 0:\n",
    "    print('Zero-watermark verification successful.')\n",
    "else:\n",
    "    print('Zero-watermark verification failed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca85d4f6-4387-493a-8bb8-eb8ef7ee4943",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
